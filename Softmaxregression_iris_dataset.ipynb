{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "id": "Fs7nc0qVhks5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "id": "uxLuaqxuhrJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "id": "c6MXMBeZhy4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a bias term to the feature matrix\n",
        "X_train_biased = np.c_[np.ones((X_train_scaled.shape[0], 1)), X_train_scaled]\n",
        "X_test_biased = np.c_[np.ones((X_test_scaled.shape[0], 1)), X_test_scaled]\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "id": "fkVGfSzSh5i-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the target variable\n",
        "num_classes = len(np.unique(y))\n",
        "y_one_hot = np.eye(num_classes)[y_train]"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "id": "47_D4xxnh-Me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax function\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "id": "awAW-9DHiFWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights\n",
        "num_features = X_train_biased.shape[1]\n",
        "num_classes = len(np.unique(y))\n",
        "weights = np.random.randn(num_features, num_classes)\n",
        "\n",
        "# Training parameters\n",
        "learning_rate = 0.01\n",
        "num_epochs = 1000\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    logits = np.dot(X_train_biased, weights)\n",
        "    probabilities = softmax(logits)\n",
        "\n",
        "    # Compute loss (cross-entropy)\n",
        "    loss = -np.sum(y_one_hot * np.log(probabilities)) / len(X_train_biased)\n",
        "\n",
        "    # Compute gradients\n",
        "    gradients = np.dot(X_train_biased.T, (probabilities - y_one_hot)) / len(X_train_biased)\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    weights -= learning_rate * gradients\n",
        "   # Print loss for every 100 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 0, Loss: 0.7876198724878628\nEpoch 100, Loss: 0.6495313807261618\nEpoch 200, Loss: 0.5563416222733442\nEpoch 300, Loss: 0.49312517410385515\nEpoch 400, Loss: 0.4488597109920474\nEpoch 500, Loss: 0.41652247747573556\nEpoch 600, Loss: 0.39186391702277085\nEpoch 700, Loss: 0.3723094468551976\nEpoch 800, Loss: 0.3562606224660867\nEpoch 900, Loss: 0.34269558410549966\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MCDATDyiP_w",
        "outputId": "2f2a3e31-233b-493b-fc57-c406e60f50cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Make predictions on the test set\n",
        "test_logits = np.dot(X_test_biased, weights)\n",
        "test_probabilities = softmax(test_logits)\n",
        "y_pred = np.argmax(test_probabilities, axis=1)\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "id": "e_zLSsjJict-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy on the test set: {accuracy}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy on the test set: 0.9333333333333333\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVkHIF4civgS",
        "outputId": "9227c731-1c12-477e-f5e1-1c52e16c6e64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An accuracy of 0.9333 on the test set indicates that  softmax regression model is performing well on the Iris dataset. This accuracy suggests that the model is making correct predictions for approximately 93.33% of the instances in the test set."
      ],
      "metadata": {
        "id": "YZP8UaNei0MA"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python",
      "language": "python",
      "display_name": "Pyolite (preview)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernel_info": {
      "name": "python"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}